{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This notebook was made too predict sotck prices with traditional machine learning algorithms and deep learning\n\n### To run this notebook ensure that you have already the dataset provided by kaggle -> daily-historical-stock-prices-1970-2018\n\n> ensure that you have the folder : \n1. /kaggle/input/daily-historical-stock-prices-1970-2018/historical_stock_prices.csv\n2. /kaggle/input/daily-historical-stock-prices-1970-2018/historical_stocks.csv"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #ploting graphics\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Starting by visualizing data;"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"missing_values = [\"n/a\", \"na\", \"--\"]\n\nstocks = pd.read_csv('../input/daily-historical-stock-prices-1970-2018/historical_stocks.csv',na_values = missing_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start with a small preview of the corresponding dataframe read previously;"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We realize there are 5 columns and this dataset:\n\n- 'ticker' corresponds to the name of the share\n- 'exchange' corresponds to the type of exchange made \n- 'name' refers the company's name\n- 'sector' refers to the actual sector where the given company operates\n- 'industry' specifies the type of services that can be provided\n\nWe also know that this dataset contains missing values :\n\n> We have missing values on columns 'sector' and 'industry'\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['ticker'].unique().size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We realize there are 6460 entries to the table, where the unique identifiers are the share's names, meaning that a company's name can show up twice if it has, throughout the established period of time, changed the name of it's stocks. We will note that, for having to change the type of exchange, the companies also changed the name of the shares;\n\n> One example of this is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks[stocks['name'] == \"1347 PROPERTY INSURANCE HOLDINGS, INC.\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing values treatment\n\n#### The first step is to identify if the companies switched their share name; in the case they did, they can then contain the sector and industry present on another row\n\n> Right now we have the following missing values:\n\n1. ticker         0\n2. exchange       0\n3. name           0\n4. sector      1440\n5. industry    1440\n\n> In a 6459 rows × 5 columns matrix\n"},{"metadata":{},"cell_type":"markdown","source":"> We want all rows that present null values, so we can obtain the names of the companies that do."},{"metadata":{"trusted":true},"cell_type":"code","source":"null_data = stocks[stocks.isnull().any(axis=1)]\nnull_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We realize that, by standard, all rows that do not have sector, do not have industry either and vice-versa."},{"metadata":{},"cell_type":"markdown","source":"### This function checks for companies that changed their ticker name\n\n> If any did, we check if there are some other instances of that same company where the sector and industry information is present."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None\nnames = null_data['name'].unique()\n\nfor companie in names:\n    \n    data = stocks[stocks['name'] == companie]\n    \n    for index,row in data.iterrows():\n        \n        if(not pd.isnull(row['sector'])):\n            \n            sector = row['sector']\n            industry = row['industry']\n            \n            tmp = stocks[stocks['name'] == row['name']]\n            tmp[\"sector\"] = tmp[\"sector\"].fillna(sector)\n            tmp['industry'] = tmp['industry'].fillna(industry)\n            stocks[stocks['name'] == row['name']] = tmp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> After this operation, we remain with a 6459 rows × 5 columns matrix, but we have different numbers of missing values, respectively:\n\n1. ticker         0\n2. exchange       0\n3. name           0\n4. sector      1018\n5. industry    1018\n6. dtype: int64"},{"metadata":{},"cell_type":"markdown","source":"### In this part, all remaining missing values will be removed from the dataset, mainly for the reason that there is not sufficient information that allows us to fill these values, given the variety of sector and industries existant.\n> We now have a 5442 rows × 5 columns matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_tickers = stocks[stocks.isnull().any(axis=1)]\n\n\nstocks = stocks.dropna(how='any',axis=0) \nstocks.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Now we only have 5442 tickers"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['ticker'].unique().size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset exploration\n\n> Predominant sectors\n\n> Predominant industries\n\n> Types of stock exchanges on which we operate"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['name'].unique().size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['exchange'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of shares in each type of exchange is rather balanced, which is good for the purpose of ML."},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['exchange'].value_counts().plot(kind='bar', title='Types of exchanges')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['sector'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks = stocks[stocks['sector'] != 'SECTOR']\nstocks.shape\n#remover a linha dummy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['sector'].value_counts().plot(kind='barh', title='Sectors')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We realize the, throughout the dataset, the Finances sector dominates the sector column, up there with Consumer services and Health care. We can also consider technology, if we allow such leverage."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=stocks['sector'].value_counts().plot(kind='pie', title='Sectors', )\nax.set_ylabel('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Industry"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks['industry'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"absolute_frequency_top10 = stocks['industry'].value_counts()[:10].copy()\nabsolute_frequency_top10 = absolute_frequency_top10.rename('')\nabsolute_frequency_top10.plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe two major industries ruling the dataset by a considerable margin: Major Pharmaceuticals and Major Banks."},{"metadata":{"trusted":true},"cell_type":"code","source":"absolute_frequency_top10.plot(kind='pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's dive down on the rate of changing in terms of share name.\n### As we said earlier, a company with the same name can have several shares names changed through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"dif_exchange_x_ticker_exchange = stocks.groupby(['name','sector','industry'])['ticker'].agg(ticker_exchange=('ticker','count'), exchange=('exchange','count'))\ndif_exchange_x_ticker= stocks.groupby(['name','sector','industry'])['ticker'].agg(ticker_exchange=('ticker','count'))\nchange_on = dif_exchange_x_ticker[dif_exchange_x_ticker['ticker_exchange'] >=2].sort_values(by='ticker_exchange', ascending=False).apply(lambda x : x-1)\nchange_off = dif_exchange_x_ticker[dif_exchange_x_ticker['ticker_exchange'] < 2].apply(lambda x : x-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dif_exchange_x_ticker_exchange","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dif_exchange_x_ticker_exchange[dif_exchange_x_ticker_exchange['exchange'] == dif_exchange_x_ticker_exchange['ticker_exchange']].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By the operation above, we see that the number of ticker names and types of exchange are the same, which tells us, by knowing that there are not equal tickers in the dataset, that change to/from either type of exchange requires rebranding of the share, so we can simply identify it by the ticker, like we did priviously. We may also consider that the ticker name might be changed for marketing purposes and maintaining it's type of exchange.\n\nIt is worth noting that we will not include the type of exchange as we consider that it doesn't add information: **for now**,we do not have dates of these changes nor the info regarding if the shares still exist or not, so we cannot identify if there's some sort of shitf in favor of any of the types of exchange. So we won't be using type of exchange on the rest of this topic."},{"metadata":{"trusted":true},"cell_type":"code","source":"change_off","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"change_on","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We produced two distinct dataframes, grouped by the companies' names, sectors and industries,respectively, and contemplate the number of changes on ticker:\n> The first one regards to the companies that did not make any changes, going by the name 'change_off'\n\n> The second one regards to the companies that made name changes in the past, going by the name 'change_on'\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=change_on.groupby('sector').mean().sort_values(by='ticker_exchange',ascending=False).plot(kind='barh',y='ticker_exchange',legend=False, title ='Sectors')\n#ax.set_ylabel('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We identify that companies on the Finances sector show a mean higher regarding the rebranding of their tickers, followed closely by Transportation and Consumer Services"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=change_on.groupby('industry').mean().sort_values(by='ticker_exchange',ascending=False)[:10].plot(kind='barh',y='ticker_exchange',legend=False, title ='Top 10 Industries')\n#ax.set_ylabel('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Industry wise, we can see that Finances show up big again, equal with Farming/Seeds/Milling. Investment Bankers/Brokers/Service follow right away."},{"metadata":{},"cell_type":"markdown","source":"We conclude the the shallow analysis of the first component of the Stock Prices dataset."},{"metadata":{},"cell_type":"markdown","source":"# Let's now explore the stock prices"},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_prices = pd.read_csv('../input/daily-historical-stock-prices-1970-2018/historical_stock_prices.csv')\nstock_prices","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Short explanation about the dataset\n\n- 'ticker' corresponds to the name of the share\n- 'open' describe the open price of that share in a specific day\n- 'close' describe the final share price in the end of a day\n- 'adj-close' it´s a tricky column, describes the ajudsted price of a share, thats normally different from the close price\n > An example of this, is when a stock splits occur. \nA stock split it's a current way used for compannies to sell more stocks, by diving the price in (x), lets say x = 2, then if one share = 10€, then, when stock split occurs, let say with a split=2, the share is equal to 5€, but in the end this 2 shares represent the same as 1 share, e.g, imagine that the companny have 10 shares, if you buy 1 share you have 1% of the company, in a stock split(split=2), if you buy 2 shares you only have 1% of the comapnny two.\n\n > A stock's price is typically affected by supply and demand of market participants. However, some corporate actions, such as stock splits, dividends / distributions and rights offerings can affect a stock's price and adjustments are needed to arrive at a technically accurate reflection of the true value of that stock.\n\n- 'low' is the lowest value paid for that share\n- 'high' is the highest value paid for that share\n- 'volume' of shares purchased in that day\n- 'date' represents the date (year-month-day)"},{"metadata":{},"cell_type":"markdown","source":"As we can notice by the table above, this dataset doesn't contain any missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_prices.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_prices[\"ticker\"].unique().size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As mentioned earlier, the ticker is the key, is this case, a ticker represents a companny.\n\n> In this dataset we have 5685 different tickers, in the previous dataset we had 5441 tickers, so we have to eliminate some tickers here.\n\n> This opperation is quite long, maybe 5 minutes.\n> Meanwhile go get a coffee"},{"metadata":{},"cell_type":"markdown","source":"## Não correr esta célula por agora"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npd.options.mode.chained_assignment = None\ntickers = bad_tickers['ticker'].unique()\n\nind = []\n\nfor index, row in stock_prices.iterrows():\n    if(row['ticker'] in tickers):\n        ind.append(index)\n        \nind = np.asarray(ind)\nstock_prices.drop(ind)\n    \n\nstock_prices[\"ticker\"].unique().size\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_prices.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">As we can expect, the adj_close isn't very corrolated with any feature.\n\n>Este trabalho serve para conseguir prever os preços de stock, até nos dias de hoje esta tarefa é quase impossível devido ao enorme conjunto de fatores que podem fazer variar este ajudsted close poder variar. Neste dataset contemos os features mais comuns e que se obtêm facilmente, como podemos imaginar é muito dificil ter todas as features relativas à mudança de preços no stock de uma empresa devido à falta de informação, quanto mais para 5685 empresas.\n\n>Iremos fazer o nosso melhor utilizando estes features para prever o ajd_close price."},{"metadata":{},"cell_type":"markdown","source":"## Let's check the rate of volumes and the mean,variance and standart deviation of the ajd_close price\n\n### As we can notice, the ajudsted close price is the key to a good trader. We want to build serveral machine learning algorithms that can accurately predict this column."},{"metadata":{"trusted":true},"cell_type":"code","source":"stock_adj_mean = stock_prices.groupby(['ticker'])['volume'].agg(Volume_of_trades=('Volume','sum'), Count_Ticker=('ticker','count'),Mean_adj_close =('adj_close', 'mean'))\nstock_adj_var = stock_prices.groupby(['ticker'])['volume'].agg(Var_adj_close =('adj_close', 'var'))\nstock_adj_std = stock_prices.groupby(['ticker'])['volume'].agg(Std_adj_close =('adj_close', 'std'))\n\n\nstocks_adj_close = stock_adj_mean.join(stock_adj_var, how = 'left', lsuffix = 'ticker').join(stock_adj_std, how = 'left', lsuffix = 'ticker')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks_adj_close","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As we can see by the table, some comapanies appear more than others.\n### We will try to predict the adjusted close price for the companies how have more tickets/rows on the dataset, by other words, we are choosing the companies with more data, for more accuract predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks_adj_close.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks_adj_close_top_10 = stocks_adj_close['Count_Ticker'].sort_values(ascending = False)[:10].copy()\nstocks_adj_close_top_10 = stocks_adj_close_top_10.rename('')\nstocks_adj_close_top_10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We want to predict the stock prices to a specific company.\n### So the first step it's to make a dataframe with a unique ticker.\n\n# Let's start by making an algorithm to predict the ajudsted close price of the HPQ"},{"metadata":{"trusted":true},"cell_type":"code","source":"def companny_stocks(ticker):\n    return stock_prices[stock_prices[\"ticker\"] == ticker]\n\ndf = companny_stocks(\"HPQ\")\ndf = df.drop([\"ticker\"],axis=1)\ndf[60:80]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Data corresponding to the company with the HPQ ticker\n> All rows are ordered by date, we can see that there are some hops, for example from 1970-04-24 to 1970-04-27, as we can see in the last two rows of this dataset, but these hops are derived from the wekends, where the trading market is closed and sometimes holidays."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([\"date\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This companie have the NYSE Exhange ad is Sector is Technology"},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks[stocks['ticker'] == 'HPQ']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some thoughs:\n\n1. Make a short explanation about the columns -> Done\n\n2. Check whats top10 tickers how have more volumes/trades on the market and take some concluisions about their sector/industry so we can have the first part of the dataset exploration consitent\n\n3. Explore the Volume and Bets Column\n\n4. Separate the stocks by ticker\n\n4. Check if the date is consistente\n"},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning algorithms"},{"metadata":{},"cell_type":"markdown","source":"1. Linear Regression\n2. Support Vectors Classifers for Regression SVR\n3. Decisions Tree / Random Forest\n4. Recurrent Neural Networks (RNN) / LSTM\n\n"},{"metadata":{},"cell_type":"markdown","source":"> First lets prepare the small dataset corresponding to the comapny HPQ:\n\n> The adj_close price column it's the label column and the rest of the features are independent variables\n\n> Lets normalize all the variables, and then make a x_train and y_train\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_distribution(df):\n    plt.figure(figsize=(70, 3))\n    i = 0\n    \n    for feature in df:\n        plt.subplot(1, 20, i+1)\n        plt.plot(df[feature])\n        plt.xlabel(feature)\n        i += 1\n    plt.show()\n\nshow_distribution(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">As we can see, all these distributions are very similar, but none of them is close to a normal distribution, so we will normalize the data using the min-max normalizer."},{"metadata":{},"cell_type":"markdown","source":"# Normalizing and splitting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(df) \n\n\ndf_normalized = scaler.transform(df)\n\nx = df_normalized[:,[0,1,3,4,5]]\ny = df_normalized[:,[2]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_normalized[:,5])\nplt.xlabel(\"volume\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(\n      x, y, test_size = 0.2, random_state=2\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\n\nregr_model = linear_model.LinearRegression(normalize = True)\nregr_model = regr_model.fit(x_train, y_train)\n\nprint(\"Coefficient:\" ,regr_model.coef_)\n\ny_pred = regr_model.predict(x_test) \n\nprint(\"Valores previstos: \" , regr_model)\nprint(\"Valores previstos: \" , y_pred)\nprint(\"Valores reais: \" , y_test)\n\nprint(\"Score: \" , regr_model.score(x_train,y_train))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> compare the actual output values for **X_test** with the predicted"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">comparison result as a bar graph using the below script\n\n>**Note**: As the number of records is huge, for representation purpose we use just 30 records."},{"metadata":{"trusted":true},"cell_type":"code","source":"result1 = result.head(30)\nresult1.plot(kind='bar',figsize=(16,10))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}